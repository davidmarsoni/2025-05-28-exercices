{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c812197",
   "metadata": {},
   "source": [
    "# Simple agent system for PDF documents\n",
    "\n",
    "This notebook demonstrates how to create a simple chatbot that can ethier generate images or answer questions.\n",
    "\n",
    "1. Load the necessary libraries and environment variables.\n",
    "2. Create the textual chatbot.\n",
    "3. Create the image generation chatbot.\n",
    "4. Ask the user for input and generate a response.\n",
    "\n",
    "\n",
    "Please try to not run this notebook to many time for the thing as each image generation cost some credits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9faa749",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, you need:\n",
    "- An OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181b925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install llama-index llama-index-llms-openai python-dotenv openai nest-asyncio nbconvert requests\n",
    "\n",
    "# Verify installations\n",
    "import importlib\n",
    "\n",
    "def check_package(package_name):\n",
    "    try:\n",
    "        importlib.import_module(package_name)\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "packages = {\n",
    "    \"llama_index\": \"llama-index core\",\n",
    "    \"llama_index.llms.openai\": \"llama-index-llms-openai\",\n",
    "    \"dotenv\": \"python-dotenv\",\n",
    "    \"openai\": \"OpenAI API\",\n",
    "    \"nest_asyncio\": \"nest-asyncio\", \n",
    "    \"nbconvert\": \"nbconvert\",\n",
    "    \"requests\": \"requests\",\n",
    "}\n",
    "\n",
    "all_installed = True\n",
    "for package, display_name in packages.items():\n",
    "    installed = check_package(package)\n",
    "    print(f\"{display_name}: {'✅ Installed' if installed else '❌ Not installed'}\")\n",
    "    all_installed = all_installed and installed\n",
    "\n",
    "if all_installed:\n",
    "    print(\"\\n✅ All required packages are installed!\")\n",
    "else:\n",
    "    print(\"\\n⚠️ Some packages are missing. Run the installation command again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fc7015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import nest_asyncio\n",
    "\n",
    "# Apply nest_asyncio to allow nested event loops (needed for some async operations)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get API keys from environment variables or set them directly\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "# If environment variables are not loaded, you can set them here\n",
    "# OPENAI_API_KEY = \"your-openai-api-key\"\n",
    "\n",
    "# Set environment variables\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY or \"\"\n",
    "\n",
    "# Verify API key is set\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"⚠️ Warning: OPENAI_API_KEY is not set\")\n",
    "else:\n",
    "    print(\"✅ API key is set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa6c425",
   "metadata": {},
   "source": [
    "# Configure the 2 LLMs\n",
    "\n",
    "Setup the OpenAI language model to be use by our LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfbf1f3",
   "metadata": {},
   "source": [
    "## Textual LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824b2767",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "# Initialize the textual LLM with LlamaIndex library for OpenAI\n",
    "# Waring : Please not change the model name to avoid errors or extreme costs\n",
    "textualChatbot = OpenAI(model=\"gpt-4.1-nano\", api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Verify LLM setup with a simple test\n",
    "response = textualChatbot.complete(\"Hello, I am a language model. \")\n",
    "print(\"LLM Test Response:\", response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1041c770",
   "metadata": {},
   "source": [
    "## Image chatbot\n",
    "\n",
    "This section creates a chatbot that can generate images based on user input. It uses the OpenAI API to generate images and display them in the notebook.\n",
    "\n",
    "This section is not build with LlamaIndex, but used the default OpenAI API to generate images. It is a simple chatbot that can generate images based on user input. It uses the OpenAI API to generate images and display them in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77815ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import datetime\n",
    "import base64\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Create an OpenAI client\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Step 1: Create the prompt as a variable\n",
    "prompt = (\n",
    "    \"Create an artistic illustration of OpenAI and LlamaIndex working together. \"\n",
    "    \"The OpenAI logo (a hexagonal knot) is connected with digital circuits to a \"\n",
    "    \"stylized llama representing LlamaIndex, all in a futuristic AI research lab.\"\n",
    ")\n",
    "\n",
    "# Step 2: Generate image using OpenAI GPT-Image-1\n",
    "print(\"Generating image with GPT-Image-1...\")\n",
    "image_response = client.images.generate(\n",
    "    model=\"gpt-image-1\",\n",
    "    prompt=prompt,\n",
    "    n=1,\n",
    "    quality=\"medium\",\n",
    "    size=\"1024x1024\",\n",
    ")\n",
    "\n",
    "# Step 3: Get the base64 encoded image and decode it\n",
    "image_base64 = image_response.data[0].b64_json\n",
    "image_bytes = base64.b64decode(image_base64)\n",
    "\n",
    "# Step 4: Save the image to a file with timestamp\n",
    "# Create timestamp for filename\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "image_dir = \"image\"\n",
    "os.makedirs(image_dir, exist_ok=True)  # Create the image directory if it doesn't exist\n",
    "image_path = os.path.join(image_dir, f\"prompt-{timestamp}.png\")\n",
    "\n",
    "# Save the image directly from the bytes\n",
    "with open(image_path, \"wb\") as f:\n",
    "    f.write(image_bytes)\n",
    "print(f\"Image saved to {image_path}\")\n",
    "\n",
    "# Display the image in the notebook if in an IPython environment\n",
    "try:\n",
    "    display(Image(image_path))\n",
    "except ImportError:\n",
    "    print(\"IPython not available for displaying the image\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb782d9",
   "metadata": {},
   "source": [
    "# Combine the 2 LLMs with a basic ask to the user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc2e83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import base64\n",
    "from openai import OpenAI\n",
    "\n",
    "# Step 1: Ask for the mode of the chatbot to the user\n",
    "def get_chatbot_mode():\n",
    "    mode = input(\"Enter the mode of the chatbot (textual/visual): \").strip().lower()\n",
    "    if mode not in [\"textual\", \"visual\"]:\n",
    "        print(\"Invalid mode. Please enter 'textual' or 'visual'.\")\n",
    "        return get_chatbot_mode()\n",
    "    return mode\n",
    "chatbot_mode = get_chatbot_mode()\n",
    "\n",
    "# Step 2: Launch the desired chatbot mode based on user input\n",
    "if chatbot_mode == \"textual\":\n",
    "    # Get the prompt from the user\n",
    "    prompt = input(\"Enter the prompt for the chatbot: \")\n",
    "    # perform the query\n",
    "    response = textualChatbot.complete(prompt)\n",
    "    # Print the response\n",
    "    print(\"Chatbot Response:\", response.text)\n",
    "    \n",
    "elif chatbot_mode == \"visual\":\n",
    "    # Create an OpenAI client\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    \n",
    "    # Get the prompt from the user\n",
    "    prompt = input(\"Enter the prompt for the visual chatbot: \")\n",
    "    \n",
    "    # Generate image using OpenAI GPT-Image-1\n",
    "    print(\"Generating image with GPT-Image-1...\")\n",
    "    image_response = client.images.generate(\n",
    "        model=\"gpt-image-1\",\n",
    "        prompt=prompt,\n",
    "        n=1,\n",
    "        quality=\"low\",\n",
    "        size=\"1024x1024\",\n",
    "    )\n",
    "    \n",
    "    # Get the base64 encoded image and decode it\n",
    "    image_base64 = image_response.data[0].b64_json\n",
    "    image_bytes = base64.b64decode(image_base64)\n",
    "    \n",
    "    # Create timestamp for filename\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    image_dir = \"image\"\n",
    "    os.makedirs(image_dir, exist_ok=True)\n",
    "    \n",
    "    # Create the image path\n",
    "    image_path = os.path.join(image_dir, f\"prompt-{timestamp}.png\")\n",
    "    \n",
    "    # Save the image directly from the bytes\n",
    "    with open(image_path, \"wb\") as f:\n",
    "        f.write(image_bytes)\n",
    "    print(f\"Image saved to {image_path}\")\n",
    "    \n",
    "    # Display the image in the notebook if in an IPython environment\n",
    "    try:\n",
    "        from IPython.display import Image, display\n",
    "        display(Image(image_path))\n",
    "    except ImportError:\n",
    "        print(\"IPython not available for displaying the image\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
