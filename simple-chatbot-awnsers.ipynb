{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c812197",
   "metadata": {},
   "source": [
    "# Simple agent system for PDF documents\n",
    "\n",
    "This notebook demonstrates how to create a simple chatbot that can either generate images or answer questions.\n",
    "\n",
    "1. Load the necessary libraries and environment variables.\n",
    "2. Create the textual chatbot.\n",
    "3. Create the image generation chatbot.\n",
    "4. Ask the user for input and generate a response.\n",
    "\n",
    "\n",
    "Please try not to run this notebook too many times for the same thing as each image generation costs some credits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9faa749",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, you need:\n",
    "- An OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181b925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install llama-index llama-index-llms-openai python-dotenv openai nest-asyncio nbconvert requests\n",
    "\n",
    "# Verify installations\n",
    "import importlib\n",
    "\n",
    "def check_package(package_name):\n",
    "    try:\n",
    "        importlib.import_module(package_name)\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "packages = {\n",
    "    \"llama_index\": \"llama-index core\",\n",
    "    \"llama_index.llms.openai\": \"llama-index-llms-openai\",\n",
    "    \"dotenv\": \"python-dotenv\",\n",
    "    \"openai\": \"OpenAI API\",\n",
    "    \"nest_asyncio\": \"nest-asyncio\", \n",
    "    \"nbconvert\": \"nbconvert\",\n",
    "    \"requests\": \"requests\",\n",
    "}\n",
    "\n",
    "all_installed = True\n",
    "for package, display_name in packages.items():\n",
    "    installed = check_package(package)\n",
    "    print(f\"{display_name}: {'✅ Installed' if installed else '❌ Not installed'}\")\n",
    "    all_installed = all_installed and installed\n",
    "\n",
    "if all_installed:\n",
    "    print(\"\\n✅ All required packages are installed!\")\n",
    "else:\n",
    "    print(\"\\n⚠️ Some packages are missing. Run the installation command again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fc7015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import nest_asyncio\n",
    "\n",
    "# Apply nest_asyncio to allow nested event loops (needed for some async operations)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get API keys from environment variables or set them directly\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "# If environment variables are not loaded, you can set them here\n",
    "# OPENAI_API_KEY = \"your-openai-api-key\"\n",
    "\n",
    "# Set environment variables\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY or \"\"\n",
    "\n",
    "# Verify API key is set\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"⚠️ Warning: OPENAI_API_KEY is not set\")\n",
    "else:\n",
    "    print(\"✅ API key is set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa6c425",
   "metadata": {},
   "source": [
    "# Configure the 2 LLMs\n",
    "\n",
    "Setup the OpenAI language model to be used by our LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfbf1f3",
   "metadata": {},
   "source": [
    "## Textual LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824b2767",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "textualChatbot = OpenAI(model=\"gpt-4.1-nano\", api_key=OPENAI_API_KEY)\n",
    "\n",
    "response = textualChatbot.complete(\"Hello, I am a language model. \")\n",
    "print(\"LLM Test Response:\", response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1041c770",
   "metadata": {},
   "source": [
    "## Image chatbot\n",
    "\n",
    "This section creates a chatbot that can generate images based on user input. It uses the OpenAI API to generate images and display them in the notebook.\n",
    "\n",
    "This section is not built with LlamaIndex, but uses the default OpenAI API to generate images. It is a simple chatbot that can generate images based on user input. It uses the OpenAI API to generate images and display them in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77815ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import datetime\n",
    "import base64\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Create an OpenAI client\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Step 1: Create the prompt as a variable\n",
    "prompt = (\n",
    "    \"Create an artistic illustration of OpenAI and LlamaIndex working together. \"\n",
    "    \"The OpenAI logo (a hexagonal knot) is connected with digital circuits to a \"\n",
    "    \"stylized llama representing LlamaIndex, all in a futuristic AI research lab.\"\n",
    ")\n",
    "\n",
    "# Step 2: Generate image using OpenAI GPT-Image-1\n",
    "print(\"Generating image with GPT-Image-1...\")\n",
    "image_response = client.images.generate(\n",
    "    model=\"gpt-image-1\",\n",
    "    prompt=prompt,\n",
    "    n=1,\n",
    "    quality=\"medium\",\n",
    "    size=\"1024x1024\",\n",
    ")\n",
    "\n",
    "# Step 3: Get the base64 encoded image and decode it\n",
    "image_base64 = image_response.data[0].b64_json\n",
    "image_bytes = base64.b64decode(image_base64)\n",
    "\n",
    "# Step 4: Save the image to a file with timestamp\n",
    "# Create timestamp for filename\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "image_dir = \"image\"\n",
    "os.makedirs(image_dir, exist_ok=True)  # Create the image directory if it doesn't exist\n",
    "image_path = os.path.join(image_dir, f\"prompt-{timestamp}.png\")\n",
    "\n",
    "# Save the image directly from the bytes\n",
    "with open(image_path, \"wb\") as f:\n",
    "    f.write(image_bytes)\n",
    "print(f\"Image saved to {image_path}\")\n",
    "\n",
    "# Display the image in the notebook if in an IPython environment\n",
    "try:\n",
    "    display(Image(image_path))\n",
    "except ImportError:\n",
    "    print(\"IPython not available for displaying the image\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb782d9",
   "metadata": {},
   "source": [
    "# Combine the 2 LLMs with a basic ask the user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc2e83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import base64\n",
    "from openai import OpenAI\n",
    "\n",
    "# Step 1: Ask the user for the mode of the chatbot\n",
    "def get_chatbot_mode():\n",
    "    mode = input(\"Enter the mode of the chatbot (textual/visual): \").strip().lower()\n",
    "    if mode not in [\"textual\", \"visual\"]:\n",
    "        print(\"Invalid mode. Please enter 'textual' or 'visual'.\")\n",
    "        return get_chatbot_mode()\n",
    "    return mode\n",
    "chatbot_mode = get_chatbot_mode()\n",
    "\n",
    "# Step 2: Launch the desired chatbot mode based on user input\n",
    "if chatbot_mode == \"textual\":\n",
    "    # Get the prompt from the user\n",
    "    prompt = input(\"Enter the prompt for the chatbot: \")\n",
    "    # perform the query\n",
    "    response = textualChatbot.complete(prompt)\n",
    "    # Print the response\n",
    "    print(\"Chatbot Response:\", response.text)\n",
    "    \n",
    "elif chatbot_mode == \"visual\":\n",
    "    # Create an OpenAI client\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    \n",
    "    # Get the prompt from the user\n",
    "    prompt = input(\"Enter the prompt for the visual chatbot: \")\n",
    "    \n",
    "    # Generate image using OpenAI GPT-Image-1\n",
    "    print(\"Generating image with GPT-Image-1...\")\n",
    "    image_response = client.images.generate(\n",
    "        model=\"gpt-image-1\",\n",
    "        prompt=prompt,\n",
    "        n=1,\n",
    "        quality=\"medium\",\n",
    "        size=\"1024x1024\",\n",
    "    )\n",
    "\n",
    "    # Get the base64 encoded image and decode it\n",
    "    image_base64 = image_response.data[0].b64_json\n",
    "    image_bytes = base64.b64decode(image_base64)\n",
    "\n",
    "    \n",
    "    # Create timestamp for filename\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    image_dir = \"image\"\n",
    "    os.makedirs(image_dir, exist_ok=True)\n",
    "    \n",
    "    # Create the image path\n",
    "    image_path = os.path.join(image_dir, f\"prompt-{timestamp}.png\")\n",
    "    \n",
    "    # Save the image directly from the bytes\n",
    "    with open(image_path, \"wb\") as f:\n",
    "        f.write(image_bytes)\n",
    "    print(f\"Image saved to {image_path}\")\n",
    "    \n",
    "    # Display the image in the notebook if in an IPython environment\n",
    "    try:\n",
    "        from IPython.display import Image, display\n",
    "        display(Image(image_path))\n",
    "    except ImportError:\n",
    "        print(\"IPython not available for displaying the image\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca175ff",
   "metadata": {},
   "source": [
    "# Bonus: Agent-Based Implementation with Tools\n",
    "\n",
    "This bonus section demonstrates how to build a more sophisticated agent that can automatically decide whether to generate text or images based on the user's query. The agent uses LlamaIndex's function calling capabilities to select the appropriate tool.\n",
    "\n",
    "Features:\n",
    "- **Intelligent tool selection**: The agent analyzes the user query and automatically chooses between text generation and image creation\n",
    "- **Function calling**: Uses LlamaIndex's function calling mechanism\n",
    "- **Structured responses**: Properly formatted outputs for both text and image generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5b0f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install additional packages for agent functionality\n",
    "!pip install llama-index-core llama-index-agent-openai\n",
    "\n",
    "# Verify agent-related packages\n",
    "import importlib\n",
    "\n",
    "def check_agent_package(package_name):\n",
    "    try:\n",
    "        importlib.import_module(package_name)\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "agent_packages = {\n",
    "    \"llama_index.core.tools\": \"llama-index core tools\",\n",
    "    \"llama_index.agent.openai\": \"llama-index-agent-openai\",\n",
    "}\n",
    "\n",
    "print(\"Checking agent packages:\")\n",
    "for package, display_name in agent_packages.items():\n",
    "    installed = check_agent_package(package)\n",
    "    print(f\"{display_name}: {'✅ Installed' if installed else '❌ Not installed'}\")\n",
    "\n",
    "print(\"\\n✅ Agent packages check complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f64f0a",
   "metadata": {},
   "source": [
    "## Creating the Tools\n",
    "\n",
    "We'll create two tools:\n",
    "1. **Text Generation Tool**: Generates text responses using the OpenAI language model\n",
    "2. **Image Generation Tool**: Creates images based on text prompts using OpenAI's image generation API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac08cd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "# Create the text generation function\n",
    "def generate_text_response(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a text response to the user's query using OpenAI's language model.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The user's question or prompt\n",
    "        \n",
    "    Returns:\n",
    "        str: Generated text response\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create the OpenAI LLM instance for text generation\n",
    "        text_llm = OpenAI(model=\"gpt-4.1-nano\", api_key=OPENAI_API_KEY)\n",
    "        response = text_llm.complete(query)\n",
    "        return f\"Text Response: {response.text}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error generating text response: {str(e)}\"\n",
    "\n",
    "# Create the text generation tool\n",
    "text_tool = FunctionTool.from_defaults(\n",
    "    fn=generate_text_response,\n",
    "    name=\"text_generator\",\n",
    "    description=\"Generate detailed text responses, explanations, stories, or answer questions. Use this for queries that require textual information, explanations, or conversational responses.\"\n",
    ")\n",
    "\n",
    "print(\"✅ Text generation tool created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ce3fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import base64\n",
    "import openai  # Import the openai module instead of the class\n",
    "\n",
    "# Create the image generation function\n",
    "def generate_image(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate an image based on the provided text prompt using OpenAI's image generation model.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): Description of the image to generate\n",
    "        \n",
    "    Returns:\n",
    "        str: Path to the generated image file and confirmation message\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create OpenAI client using the module\n",
    "        client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "        \n",
    "        # Generate image using OpenAI\n",
    "        print(f\"Generating image for prompt: '{prompt}'...\")\n",
    "        image_response = client.images.generate(\n",
    "            model=\"gpt-image-1\",\n",
    "            prompt=prompt,\n",
    "            n=1,\n",
    "            quality=\"medium\",\n",
    "            size=\"1024x1024\",\n",
    "        )\n",
    "        print(\"Image generation completed.\")\n",
    "        \n",
    "        # Get the base64 encoded image and decode it\n",
    "        image_base64 = image_response.data[0].b64_json\n",
    "        image_bytes = base64.b64decode(image_base64)\n",
    "        \n",
    "        # Create timestamp for filename\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        image_dir = \"image\"\n",
    "        os.makedirs(image_dir, exist_ok=True)\n",
    "        \n",
    "        # Create the image path\n",
    "        image_path = os.path.join(image_dir, f\"agent-generated-{timestamp}.png\")\n",
    "        \n",
    "        # Save the image\n",
    "        with open(image_path, \"wb\") as f:\n",
    "            f.write(image_bytes)\n",
    "        \n",
    "        # Try to display the image in the notebook\n",
    "        try:\n",
    "            from IPython.display import Image, display\n",
    "            display(Image(image_path))\n",
    "        except ImportError:\n",
    "            pass\n",
    "        \n",
    "        return f\"Image generated successfully! Saved to: {image_path}\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error generating image: {str(e)}\"\n",
    "\n",
    "# Create the image generation tool\n",
    "image_tool = FunctionTool.from_defaults(\n",
    "    fn=generate_image,\n",
    "    name=\"image_generator\", \n",
    "    description=\"Generate images, artwork, illustrations, or visual content based on text descriptions. Use this for requests that ask for visual content, pictures, images, drawings, or artwork.\"\n",
    ")\n",
    "\n",
    "print(\"✅ Image generation tool created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c201bc",
   "metadata": {},
   "source": [
    "## Creating the Intelligent Agent\n",
    "\n",
    "Now we'll create an agent that can automatically choose between text and image generation based on the user's query. The agent will analyze the intent and select the appropriate tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dc32e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent.openai import OpenAIAgent\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "# Create the LLM for the agent (with function calling capabilities)\n",
    "agent_llm = OpenAI(\n",
    "    model=\"gpt-4.1-nano\", \n",
    "    api_key=OPENAI_API_KEY,\n",
    "    temperature=0.3  \n",
    ")\n",
    "\n",
    "# Create the agent with both tools\n",
    "agent = OpenAIAgent.from_tools(\n",
    "    tools=[text_tool, image_tool],\n",
    "    llm=agent_llm,\n",
    "    verbose=True,\n",
    "    system_prompt=\"\"\"You are an intelligent assistant that can either generate text responses or create images based on user queries.\n",
    "\n",
    "Analyze the user's request carefully and choose the appropriate tool:\n",
    "\n",
    "1. Use the TEXT GENERATOR tool for:\n",
    "   - Questions requiring explanations, information, or analysis\n",
    "   - Requests for stories, essays, or written content\n",
    "   - Conversational responses\n",
    "   - Technical or factual questions\n",
    "   - Any query that needs a textual response\n",
    "\n",
    "2. Use the IMAGE GENERATOR tool for:\n",
    "   - Requests to create, draw, generate, or make images/pictures\n",
    "   - Descriptions that ask for visual content or artwork\n",
    "   - Requests containing words like \"image\", \"picture\", \"draw\", \"create art\", \"visualize\", \"illustration\"\n",
    "   - Any query that explicitly asks for visual output\n",
    "\n",
    "Always choose the most appropriate tool based on the user's intent. If the user asks for both text and images, prioritize based on the primary intent of their message.\"\"\"\n",
    ")\n",
    "\n",
    "print(\"✅ Intelligent agent created successfully!\")\n",
    "print(\"Agent can now automatically choose between text and image generation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6677f77f",
   "metadata": {},
   "source": [
    "## Testing the Agent\n",
    "\n",
    "Let's test the agent with some example queries to see how it automatically selects the appropriate tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e40700b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Text-based query\n",
    "print(\"Text Query\")\n",
    "print(\"=\" * 50)\n",
    "text_query = \"Explain the benefits of artificial intelligence in education\"\n",
    "text_response = agent.chat(text_query)\n",
    "print(f\"Query: {text_query}\")\n",
    "print(f\"Response: {text_response}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4817bfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Image generation query\n",
    "print(\"Image Query\")\n",
    "print(\"=\" * 50)\n",
    "image_query = \"Create an image of a futuristic classroom with AI teaching assistants\"\n",
    "# Uncomment the next line to test image generation\n",
    "# image_response = agent.chat(image_query)\n",
    "print(f\"Query: {image_query}\")\n",
    "print(f\"Response: {image_response}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6285b312",
   "metadata": {},
   "source": [
    "## Interactive Agent Usage\n",
    "\n",
    "Now you can interact with the agent! It will automatically determine whether your query needs text or image generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78f2c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive agent session\n",
    "def chat_with_agent():\n",
    "    \"\"\"\n",
    "    Interactive function to chat with the intelligent agent.\n",
    "    The agent will automatically choose between text and image generation.\n",
    "    \"\"\"\n",
    "    print(\"Welcome to the Intelligent Agent!\")\n",
    "    print(\"I can generate text responses or create images based on your queries.\")\n",
    "    print(\"Type 'quit' to exit.\\n\")\n",
    "    \n",
    "    while True:\n",
    "        # Get user input\n",
    "        user_query = input(\"Your query: \").strip()\n",
    "        \n",
    "        # Check for exit condition\n",
    "        if user_query.lower() in ['quit', 'exit', 'bye']:\n",
    "            print(\"Goodbye! Thanks for using the intelligent agent!\")\n",
    "            break\n",
    "            \n",
    "        if not user_query:\n",
    "            print(\"Please enter a valid query.\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Let the agent process the query and choose the appropriate tool\n",
    "            print(f\"\\nProcessing: '{user_query}'\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "            response = agent.chat(user_query)\n",
    "            print(f\"\\nAgent Response: {response}\")\n",
    "            print(\"=\" * 60)\n",
    "            print()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing query: {str(e)}\")\n",
    "            print()\n",
    "\n",
    "# Run the interactive session\n",
    "# Uncomment the line below to start the interactive chat\n",
    "#chat_with_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba03438",
   "metadata": {},
   "source": [
    "## Summary of Bonus Agent Features\n",
    "\n",
    "### What We Built\n",
    "This bonus section demonstrates an advanced **intelligent agent system** that automatically chooses between text and image generation tools based on user queries.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
