{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f338d72",
   "metadata": {},
   "source": [
    "# Simple agent system for PDF documents\n",
    "\n",
    "This notebook demonstrates how to create a simple agent system for PDF documents.\n",
    "\n",
    "1. Load a PDF document.\n",
    "2. Split the document into chunks.\n",
    "3. Create an embedding of the chunks.\n",
    "4. Create a language model.\n",
    "5. Create an agent that uses the retriever and language model to answer questions about the document.\n",
    "6. Ask questions of the agent and get answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff391f1",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, you need:\n",
    "- An OpenAI API key\n",
    "- PDF documents to query  (by default there is allready 2 PDF documents in the `pdf` folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b9d0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install llama-index llama-index-llms-openai python-dotenv openai nest-asyncio nbconvert requests\n",
    "\n",
    "# Verify installations\n",
    "import importlib\n",
    "\n",
    "def check_package(package_name):\n",
    "    try:\n",
    "        importlib.import_module(package_name)\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "packages = {\n",
    "    \"llama_index\": \"llama-index core\",\n",
    "    \"llama_index.llms.openai\": \"llama-index-llms-openai\",\n",
    "    \"dotenv\": \"python-dotenv\",\n",
    "    \"openai\": \"OpenAI API\",\n",
    "    \"nest_asyncio\": \"nest-asyncio\", \n",
    "    \"nbconvert\": \"nbconvert\",\n",
    "    \"requests\": \"requests\",\n",
    "}\n",
    "\n",
    "all_installed = True\n",
    "for package, display_name in packages.items():\n",
    "    installed = check_package(package)\n",
    "    print(f\"{display_name}: {'✅ Installed' if installed else '❌ Not installed'}\")\n",
    "    all_installed = all_installed and installed\n",
    "\n",
    "if all_installed:\n",
    "    print(\"\\n✅ All required packages are installed!\")\n",
    "else:\n",
    "    print(\"\\n⚠️ Some packages are missing. Run the installation command again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602d3223",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Load environment variables from the `.env` file and set up for PDF processing. <br>\n",
    "N.b. it will look through the entire repo for a valid `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a98033c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import nest_asyncio\n",
    "\n",
    "# Apply nest_asyncio to allow nested event loops (needed for some async operations)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get API keys from environment variables or set them directly\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# If environment variables are not loaded, you can set them here\n",
    "# OPENAI_API_KEY = \"your-openai-api-key\"\n",
    "\n",
    "# Set environment variables\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY or \"\"\n",
    "\n",
    "# Verify API key is set\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"⚠️ Warning: OPENAI_API_KEY is not set\")\n",
    "else:\n",
    "    print(\"✅ API key is set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9957a26",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "\n",
    "Let's import all the libraries we'll need for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4ac01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import core LlamaIndex components\n",
    "from llama_index.core import SimpleDirectoryReader, Settings, VectorStoreIndex\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core.query_engine import SubQuestionQueryEngine\n",
    "\n",
    "# Import OpenAI LLM\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "# Import other utilities\n",
    "import logging\n",
    "import sys\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Configure basic logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "print(\"✅ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755b6555",
   "metadata": {},
   "source": [
    "## Configure LLM\n",
    "\n",
    "Set up the language model we'll use for our queries and indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c837b29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenAI LLM\n",
    "llm = OpenAI(\n",
    "    model=\"gpt-4.1-nano\",  # You can change this to another model if needed\n",
    "    temperature=0.2,      # Lower temperature for more consistent results\n",
    "    streaming=True,       # Enable streaming for better UX\n",
    "    system_prompt=\"You are a helpful assistant that provides accurate information about topics found in documents. Be thorough and make sure to search through the entire document, including any lists or tables that might appear on pages.\"\n",
    ")\n",
    "\n",
    "# Set up the global LlamaIndex configuration\n",
    "Settings.llm = llm\n",
    "\n",
    "print(f\"✅ LLM configured: {llm.model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75be0a9",
   "metadata": {},
   "source": [
    "## Load and Index PDF Documents\n",
    "\n",
    "Let's load some PDF documents and create vector indices for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d595d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to our PDF files\n",
    "# Update these paths to match your file locations\n",
    "pdf_paths = {\n",
    "    \"brochure-info-gestion\":\"pdf/hesso-brochure-a5-info-gestion-fr-web.pdf\",\n",
    "    \"brochure-eco-entreprise\":\"pdf/hesso-brochure-a5-eco-entreprise-fr-web-cor2.pdf\"\n",
    "} \n",
    "\n",
    "# Check if the files exist\n",
    "pdf_exists = {}\n",
    "for key, path in pdf_paths.items():\n",
    "    exists = os.path.exists(path)\n",
    "    pdf_exists[key] = exists\n",
    "    if not exists:\n",
    "        print(f\"⚠️ Warning: {key} PDF file not found at {path}\")\n",
    "\n",
    "# Only proceed with files that exist\n",
    "pdf_documents = {}\n",
    "pdf_indices = {}\n",
    "\n",
    "for key, path in pdf_paths.items():\n",
    "    if pdf_exists[key]:\n",
    "        try:\n",
    "            print(f\"Loading {key} document...\")\n",
    "            # Set a higher chunk_size to ensure we capture tables and lists properly\n",
    "            pdf_documents[key] = SimpleDirectoryReader(\n",
    "                input_files=[path],\n",
    "                filename_as_id=True\n",
    "            ).load_data()\n",
    "            print(f\"✅ Successfully loaded {len(pdf_documents[key])} pages from {key}\")\n",
    "            \n",
    "            print(f\"Creating vector index for {key}...\")\n",
    "            pdf_indices[key] = VectorStoreIndex.from_documents(pdf_documents[key])\n",
    "            print(f\"✅ Successfully created index for {key}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading {key}: {e}\")\n",
    "\n",
    "print(f\"Total PDF indices created: {len(pdf_indices)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d176b8",
   "metadata": {},
   "source": [
    "## Create Query Engines\n",
    "\n",
    "Let's create individual query engines for each PDF source, then combine them into a SubQuestionQueryEngine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddc2e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create query engines for each PDF index\n",
    "pdf_query_engines = {}\n",
    "for key, index in pdf_indices.items():\n",
    "    # the parameter similarity_top_k is set to 10 to return the top 10 most relevant results if you need more you can increase this number\n",
    "    # But be careful with the number of tokens you are using the higher the number of top_k the more tokens you will use -> more expensive and slower\n",
    "    pdf_query_engines[key] = index.as_query_engine(similarity_top_k=10)\n",
    "\n",
    "# Create a list of query engine tools\n",
    "query_engine_tools = []\n",
    "\n",
    "# Add PDF query engines to the tools list\n",
    "for key, engine in pdf_query_engines.items():\n",
    "    display_name = key.replace(\"_\", \" \").title()\n",
    "    query_engine_tools.append(\n",
    "        # Create a QueryEngineTool for each PDF query engine\n",
    "        # This allows us to query each PDF source\n",
    "        QueryEngineTool(\n",
    "            query_engine=engine,\n",
    "            metadata=ToolMetadata(\n",
    "                name=key, \n",
    "                description=f\"Provides comprehensive information about {display_name}\"\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(f\"✅ Created {len(query_engine_tools)} query engine tools\")\n",
    "\n",
    "# Create the SubQuestionQueryEngine\n",
    "multi_source_engine = SubQuestionQueryEngine.from_defaults(\n",
    "    query_engine_tools=query_engine_tools\n",
    ")\n",
    "\n",
    "print(\"✅ Created SubQuestionQueryEngine that can query across all PDF sources\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99756cf9",
   "metadata": {},
   "source": [
    "## Query Your PDF Documents\n",
    "\n",
    "Now we can query all our PDF data sources at once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fc6538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_system(query_text):\n",
    "    \"\"\"Query the multi-source PDF system and display the response.\"\"\"\n",
    "    print(f\"Querying: '{query_text}'\")\n",
    "    print(\"\\nThinking...\\n\")\n",
    "    \n",
    "    # Set logging to DEBUG to show the sub-questions\n",
    "    logging.getLogger().setLevel(logging.DEBUG)\n",
    "    \n",
    "    # Execute the query\n",
    "    response = multi_source_engine.query(query_text)\n",
    "    \n",
    "    # Reset logging level\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "    \n",
    "    # Display the response\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "    display(Markdown(f\"**Answer:**\\n\\n{response}\"))\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Example query about HES-SO fields of study\n",
    "if \"brochure-info-gestion\" in pdf_query_engines:\n",
    "    query_text = \"What is the Bachelor's degree in Business Information Technology ?\"\n",
    "    response = query_system(query_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaa7bfe",
   "metadata": {},
   "source": [
    "N.b. here you can see that the query engine is not able to understand the different sources of the PDF documents. It seems to think that the two documents are one document. This is a limitation of the current implementation of the query engine. <br>\n",
    "To query the document separately see the section below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74391526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a query that query multiple sources\n",
    "if len(query_engine_tools) > 1:\n",
    "    query_text = \"List all the bachelor programs of your context ?\"\n",
    "    response = query_system(query_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f475d1df",
   "metadata": {},
   "source": [
    "## Querying Specific PDF Sources\n",
    "\n",
    "You can also query individual PDF sources directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfd4fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query just one of the PDF indices\n",
    "if \"brochure-info-gestion\" in pdf_query_engines:\n",
    "    print(\"Querying just the first PDF index\")\n",
    "    inf_gestion_engine = pdf_query_engines[\"brochure-info-gestion\"]\n",
    "    \n",
    "    query_text = \"What is the Bachelor's degree in Business Information Technology ? please provide a bullet point list\"\n",
    "    response = inf_gestion_engine.query(query_text)\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "    display(Markdown(f\"**Response:**\\n\\n{response}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285e1705",
   "metadata": {},
   "source": [
    "N.b. Here the result are more accurate because the query engine has only one document to work with."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
