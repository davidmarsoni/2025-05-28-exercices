{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f338d72",
   "metadata": {},
   "source": [
    "# Simple agent system for PDF documents\n",
    "\n",
    "This notebook demonstrates how to create a simple agent system for PDF documents.\n",
    "\n",
    "1. Load a PDF document.\n",
    "2. Split the document into chunks.\n",
    "3. Create an embedding of the chunks.\n",
    "4. Create a language model.\n",
    "5. Create an agent that uses the retriever and language model to answer questions about the document.\n",
    "6. Ask questions of the agent and get answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff391f1",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, you need:\n",
    "- An OpenAI API key\n",
    "- PDF documents to query  (by default there are already 2 PDF documents in the `pdf` folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b9d0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install llama-index llama-index-llms-openai python-dotenv openai nest-asyncio nbconvert requests\n",
    "\n",
    "# Verify installations\n",
    "import importlib\n",
    "\n",
    "def check_package(package_name):\n",
    "    try:\n",
    "        importlib.import_module(package_name)\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "packages = {\n",
    "    \"llama_index\": \"llama-index core\",\n",
    "    \"llama_index.llms.openai\": \"llama-index-llms-openai\",\n",
    "    \"dotenv\": \"python-dotenv\",\n",
    "    \"openai\": \"OpenAI API\",\n",
    "    \"nest_asyncio\": \"nest-asyncio\", \n",
    "    \"nbconvert\": \"nbconvert\",\n",
    "    \"requests\": \"requests\",\n",
    "}\n",
    "\n",
    "all_installed = True\n",
    "for package, display_name in packages.items():\n",
    "    installed = check_package(package)\n",
    "    print(f\"{display_name}: {'✅ Installed' if installed else '❌ Not installed'}\")\n",
    "    all_installed = all_installed and installed\n",
    "\n",
    "if all_installed:\n",
    "    print(\"\\n✅ All required packages are installed!\")\n",
    "else:\n",
    "    print(\"\\n⚠️ Some packages are missing. Run the installation command again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602d3223",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Load environment variables from the `.env` file and set up for PDF processing. <br>\n",
    "N.b. it will look through the entire repo for a valid `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a98033c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import nest_asyncio\n",
    "\n",
    "# Apply nest_asyncio to allow nested event loops (needed for some async operations)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get API keys from environment variables or set them directly\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# If environment variables are not loaded, you can set them here\n",
    "# OPENAI_API_KEY = \"your-openai-api-key\"\n",
    "\n",
    "# Set environment variables\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY or \"\"\n",
    "\n",
    "# Verify API key is set\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"⚠️ Warning: OPENAI_API_KEY is not set\")\n",
    "else:\n",
    "    print(\"✅ API key is set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9957a26",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "\n",
    "Let's import all the libraries we'll need for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4ac01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import core LlamaIndex components\n",
    "from llama_index.core import SimpleDirectoryReader, Settings, VectorStoreIndex\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core.query_engine import SubQuestionQueryEngine\n",
    "\n",
    "# Import OpenAI LLM\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "# Import other utilities\n",
    "import logging\n",
    "import sys\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Configure basic logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "print(\"✅ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755b6555",
   "metadata": {},
   "source": [
    "## Configure LLM\n",
    "\n",
    "Set up the language model we'll use for our queries and indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c837b29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenAI LLM\n",
    "\n",
    "## Exercise 1 : Try to create the LLM with these parameters\n",
    "model=\"gpt-4.1-nano\", \n",
    "temperature=0.2,      \n",
    "streaming=True,     \n",
    "system_prompt=\"You are a helpful assistant that provides accurate information about topics found in documents. Be thorough and make sure to search through the entire document, including any lists or tables that might appear on pages.\"\n",
    "\n",
    "## YOUR CODE HERE\n",
    "\n",
    "# Some documentation to help you:\n",
    "# - https://docs.llamaindex.ai/en/stable/examples/llm/openai/#configure-model\n",
    "\n",
    "\n",
    "\n",
    "# Exercise 2 : Set up the global LlamaIndex configuration\n",
    "\n",
    "## YOUR CODE HERE one line :)\n",
    "\n",
    "# Some documentation to help you:\n",
    "# - https://docs.llamaindex.ai/en/stable/module_guides/supporting_modules/settings/#configuring-settings\n",
    "\n",
    "print(f\"✅ LLM configured: {llm.model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75be0a9",
   "metadata": {},
   "source": [
    "## Load and Index PDF Documents\n",
    "\n",
    "Let's load some PDF documents and create vector indices for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d595d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is already provided for you. Please read it to understand it as the main goal of this notebook is to create an \n",
    "# LLM that can answer questions about the documents you will provide, not creating the index itself.\n",
    "# ======================================================================\n",
    "\n",
    "# Define the paths to our PDF files\n",
    "# Update these paths to match your file locations\n",
    "pdf_paths = {\n",
    "    \"brochure-info-gestion\":\"pdf/hesso-brochure-a5-info-gestion-fr-web.pdf\",\n",
    "    \"brochure-eco-entreprise\":\"pdf/hesso-brochure-a5-eco-entreprise-fr-web-cor2.pdf\"\n",
    "} \n",
    "\n",
    "# Check if the files exist\n",
    "pdf_exists = {}\n",
    "for key, path in pdf_paths.items():\n",
    "    exists = os.path.exists(path)\n",
    "    pdf_exists[key] = exists\n",
    "    if not exists:\n",
    "        print(f\"⚠️ Warning: {key} PDF file not found at {path}\")\n",
    "\n",
    "# Only proceed with files that exist\n",
    "pdf_documents = {}\n",
    "pdf_indices = {}\n",
    "\n",
    "for key, path in pdf_paths.items():\n",
    "    if pdf_exists[key]:\n",
    "        try:\n",
    "            print(f\"Loading {key} document...\")\n",
    "            # Set a higher chunk_size to ensure we capture tables and lists properly\n",
    "            pdf_documents[key] = SimpleDirectoryReader(\n",
    "                input_files=[path],\n",
    "                filename_as_id=True\n",
    "            ).load_data()\n",
    "            print(f\"✅ Successfully loaded {len(pdf_documents[key])} pages from {key}\")\n",
    "            \n",
    "            print(f\"Creating vector index for {key}...\")\n",
    "            pdf_indices[key] = VectorStoreIndex.from_documents(pdf_documents[key])\n",
    "            print(f\"✅ Successfully created index for {key}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading {key}: {e}\")\n",
    "\n",
    "print(f\"Total PDF indices created: {len(pdf_indices)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d176b8",
   "metadata": {},
   "source": [
    "## Create Query Engines\n",
    "\n",
    "Let's create individual query engines for each PDF source, then combine them into a SubQuestionQueryEngine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddc2e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create query engines for each PDF index\n",
    "pdf_query_engines = {}\n",
    "for key, index in pdf_indices.items():\n",
    "    # the parameter similarity_top_k is set to 10 to return the top 10 most relevant results if you need more you can increase this number\n",
    "    # But be careful with the number of tokens you are using the higher the number of top_k the more tokens you will use -> more expensive and slower\n",
    "    pdf_query_engines[key] = index.as_query_engine(similarity_top_k=10)\n",
    "\n",
    "# Create a list of query engine tools\n",
    "query_engine_tools = []\n",
    "\n",
    "# Add PDF query engines to the tools list\n",
    "for key, engine in pdf_query_engines.items():\n",
    "    display_name = key.replace(\"_\", \" \").title()\n",
    "    \n",
    "    query_engine_tools.append(\n",
    "        # Exercise 3 : Create a QueryEngineTool for each PDF query engine\n",
    "        # This allows us to query each PDF source\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        # Some documentation to help you:\n",
    "        # - https://docs.llamaindex.ai/en/stable/module_guides/deploying/agents/tools/#queryenginetool\n",
    "        # - https://docs.llamaindex.ai/en/stable/api_reference/tools/query_engine/#llama_index.core.tools.query_engine.QueryEngineTool\n",
    "        # - https://docs.llamaindex.ai/en/stable/api_reference/tools/#llama_index.core.tools.types.ToolMetadata\n",
    "      \n",
    "      \n",
    "    )\n",
    "\n",
    "print(f\"✅ Created {len(query_engine_tools)} query engine tools\")\n",
    "\n",
    "# Exercise 4 : Create a SubQuestionQueryEngine called \"multi_source_engine\" that can query across all PDF sources. It needs the query engine tools defined above\n",
    "\n",
    "## YOUR CODE HERE\n",
    "\n",
    "# Some documentation to help you:\n",
    "# - https://docs.llamaindex.ai/en/stable/examples/cookbooks/oreilly_course_cookbooks/Module-6/Router_And_SubQuestion_QueryEngine/#pydanticsingleselector\n",
    "\n",
    "print(\"✅ Created SubQuestionQueryEngine that can query across all PDF sources\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99756cf9",
   "metadata": {},
   "source": [
    "## Query Your PDF Documents\n",
    "\n",
    "Now we can query all our PDF data sources at once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fc6538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5 : Try to query the multi_source_engine with a question about the documents you provided\n",
    "\n",
    "## YOUR CODE HERE\n",
    "\n",
    "# Some documentation to help you:\n",
    "# - https://docs.llamaindex.ai/en/stable/module_guides/deploying/query_engine/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f475d1df",
   "metadata": {},
   "source": [
    "## Querying Specific PDF Sources\n",
    "\n",
    "You can also query individual PDF sources directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfd4fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query just one of the PDF indices\n",
    "if \"brochure-info-gestion\" in pdf_query_engines:\n",
    "   \n",
    "    # Exercise 6 : Try to query the pdf_query_engines[\"brochure-info-gestion\"] with a question about the documents you provided\n",
    "    \n",
    "    ## YOUR CODE HERE\n",
    "    \n",
    "    # Some documentation to help you:\n",
    "    # - https://docs.llamaindex.ai/en/stable/module_guides/deploying/query_engine/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285e1705",
   "metadata": {},
   "source": [
    "N.b. Here the results are more accurate because the query engine has only one document to work with."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
