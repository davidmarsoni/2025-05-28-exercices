{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f338d72",
   "metadata": {},
   "source": [
    "# Simple agent system for PDF documents\n",
    "\n",
    "This notebook demonstrates how to create a simple agent system for PDF documents.\n",
    "\n",
    "1. Load a PDF document.\n",
    "2. Split the document into chunks.\n",
    "3. Create an embedding of the chunks.\n",
    "4. Create a language model.\n",
    "5. Create an agent that uses the retriever and language model to answer questions about the document.\n",
    "6. Ask questions of the agent and get answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff391f1",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, you need:\n",
    "- An OpenAI API key\n",
    "- PDF documents to query  (by default there are already 2 PDF documents in the `pdf` folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b9d0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install llama-index llama-index-llms-openai llama-index-agent-openai python-dotenv openai nest-asyncio nbconvert requests\n",
    "\n",
    "# Verify installations\n",
    "import importlib\n",
    "\n",
    "def check_package(package_name):\n",
    "    try:\n",
    "        importlib.import_module(package_name)\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "packages = {\n",
    "    \"llama_index\": \"llama-index core\",\n",
    "    \"llama_index.llms.openai\": \"llama-index-llms-openai\",\n",
    "    \"llama_index.agent.openai\": \"llama-index-agent-openai\",\n",
    "    \"dotenv\": \"python-dotenv\",\n",
    "    \"openai\": \"OpenAI API\",\n",
    "    \"nest_asyncio\": \"nest-asyncio\", \n",
    "    \"nbconvert\": \"nbconvert\",\n",
    "    \"requests\": \"requests\",\n",
    "}\n",
    "\n",
    "all_installed = True\n",
    "for package, display_name in packages.items():\n",
    "    installed = check_package(package)\n",
    "    print(f\"{display_name}: {'✅ Installed' if installed else '❌ Not installed'}\")\n",
    "    all_installed = all_installed and installed\n",
    "\n",
    "if all_installed:\n",
    "    print(\"\\n✅ All required packages are installed!\")\n",
    "else:\n",
    "    print(\"\\n⚠️ Some packages are missing. Run the installation command again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602d3223",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Load environment variables from the `.env` file and set up for PDF processing. <br>\n",
    "N.b. it will look through the entire repo for a valid `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a98033c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import nest_asyncio\n",
    "\n",
    "# Apply nest_asyncio to allow nested event loops (needed for some async operations)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get API keys from environment variables or set them directly\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# If environment variables are not loaded, you can set them here\n",
    "# OPENAI_API_KEY = \"your-openai-api-key\"\n",
    "\n",
    "# Set environment variables\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY or \"\"\n",
    "\n",
    "# Verify API key is set\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"⚠️ Warning: OPENAI_API_KEY is not set\")\n",
    "else:\n",
    "    print(\"✅ API key is set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9957a26",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "\n",
    "Let's import all the libraries we'll need for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4ac01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import core LlamaIndex components\n",
    "from llama_index.core import SimpleDirectoryReader, Settings, VectorStoreIndex\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "\n",
    "# Import agent components\n",
    "from llama_index.agent.openai import OpenAIAgent\n",
    "\n",
    "# Import OpenAI LLM\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "# Import other utilities\n",
    "import logging\n",
    "import sys\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Configure basic logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "print(\"✅ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755b6555",
   "metadata": {},
   "source": [
    "## Configure LLM\n",
    "\n",
    "Set up the language model we'll use for our queries and indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c837b29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenAI LLM\n",
    "\n",
    "## Exercise 1 : Create the LLM with these parameters:\n",
    "# model=\"gpt-4.1-nano\"  \n",
    "# temperature=0.2      \n",
    "# streaming=True     \n",
    "# system_prompt=\"You are a helpful assistant that provides accurate information about topics found in documents. Be thorough and make sure to search through the entire document, including any lists or tables that might appear on pages.\"\n",
    "\n",
    "## YOUR CODE HERE\n",
    "# llm = ...\n",
    "\n",
    "# Some documentation to help you:\n",
    "# - https://docs.llamaindex.ai/en/stable/examples/llm/openai/#configure-model\n",
    "\n",
    "\n",
    "\n",
    "# Exercise 2 : Set up the global LlamaIndex configuration\n",
    "\n",
    "## YOUR CODE HERE (one line)\n",
    "# Settings.llm = ...\n",
    "\n",
    "# Some documentation to help you:\n",
    "# - https://docs.llamaindex.ai/en/stable/module_guides/supporting_modules/settings/#configuring-settings\n",
    "\n",
    "print(f\"✅ LLM configured: {llm.model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75be0a9",
   "metadata": {},
   "source": [
    "## Load and Index PDF Documents\n",
    "\n",
    "Let's load some PDF documents and create vector indices for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d595d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is already provided for you. Please read it to understand it as the main goal of this notebook is to create an \n",
    "# LLM that can answer questions about the documents you will provide, not creating the index itself.\n",
    "# ======================================================================\n",
    "\n",
    "# Define the paths to our PDF files\n",
    "# Update these paths to match your file locations\n",
    "pdf_paths = {\n",
    "    \"brochure-info-gestion\":\"pdf/hesso-brochure-a5-info-gestion-fr-web.pdf\",\n",
    "    \"brochure-eco-entreprise\":\"pdf/hesso-brochure-a5-eco-entreprise-fr-web-cor2.pdf\"\n",
    "} \n",
    "\n",
    "# Check if the files exist\n",
    "pdf_exists = {}\n",
    "for key, path in pdf_paths.items():\n",
    "    exists = os.path.exists(path)\n",
    "    pdf_exists[key] = exists\n",
    "    if not exists:\n",
    "        print(f\"⚠️ Warning: {key} PDF file not found at {path}\")\n",
    "\n",
    "# Only proceed with files that exist\n",
    "pdf_documents = {}\n",
    "pdf_indices = {}\n",
    "\n",
    "for key, path in pdf_paths.items():\n",
    "    if pdf_exists[key]:\n",
    "        try:\n",
    "            print(f\"Loading {key} document...\")\n",
    "            # Set a higher chunk_size to ensure we capture tables and lists properly\n",
    "            pdf_documents[key] = SimpleDirectoryReader(\n",
    "                input_files=[path],\n",
    "                filename_as_id=True\n",
    "            ).load_data()\n",
    "            print(f\"✅ Successfully loaded {len(pdf_documents[key])} pages from {key}\")\n",
    "            \n",
    "            print(f\"Creating vector index for {key}...\")\n",
    "            pdf_indices[key] = VectorStoreIndex.from_documents(pdf_documents[key])\n",
    "            print(f\"✅ Successfully created index for {key}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading {key}: {e}\")\n",
    "\n",
    "print(f\"Total PDF indices created: {len(pdf_indices)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d176b8",
   "metadata": {},
   "source": [
    "## Create Agent with Query Tools\n",
    "\n",
    "Let's create individual query engines for each PDF source, then create an OpenAI agent that can use these tools to answer questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddc2e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create query engines for each PDF index\n",
    "pdf_query_engines = {}\n",
    "for key, index in pdf_indices.items():\n",
    "    # the parameter similarity_top_k is set to 10 to return the top 10 most relevant results if you need more you can increase this number\n",
    "    # But be careful with the number of tokens you are using the higher the number of top_k the more tokens you will use -> more expensive and slower\n",
    "    pdf_query_engines[key] = index.as_query_engine(similarity_top_k=10)\n",
    "\n",
    "# Create a list of query engine tools\n",
    "query_engine_tools = []\n",
    "\n",
    "# Add PDF query engines to the tools list\n",
    "for key, engine in pdf_query_engines.items():\n",
    "    display_name = key.replace(\"_\", \" \").title()\n",
    "    \n",
    "    # Exercise 3 : Create a QueryEngineTool for each PDF query engine\n",
    "    # This allows us to query each PDF source\n",
    "    \n",
    "    ## YOUR CODE HERE\n",
    "    \n",
    "    # Some documentation to help you:\n",
    "    # - https://docs.llamaindex.ai/en/stable/module_guides/deploying/agents/tools/#queryenginetool\n",
    "    # - https://docs.llamaindex.ai/en/stable/api_reference/tools/query_engine/#llama_index.core.tools.query_engine.QueryEngineTool\n",
    "    # - https://docs.llamaindex.ai/en/stable/api_reference/tools/#llama_index.core.tools.types.ToolMetadata\n",
    "\n",
    "print(f\"✅ Created {len(query_engine_tools)} query engine tools\")\n",
    "\n",
    "# Exercise 4 : Create an OpenAI Agent called \"agent\" that can use the query tools to answer questions\n",
    "# The agent should have access to all the query_engine_tools and use the llm we configured\n",
    "\n",
    "## YOUR CODE HERE\n",
    "\n",
    "# Some documentation to help you:\n",
    "# - https://docs.llamaindex.ai/en/stable/examples/agent/openai_agent/#openai-agent\n",
    "# - https://docs.llamaindex.ai/en/stable/api_reference/agent/openai/#llama_index.agent.openai.OpenAIAgent\n",
    "\n",
    "print(\"✅ Created OpenAI Agent that can query across all PDF sources using tools\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99756cf9",
   "metadata": {},
   "source": [
    "## Query Your PDF Documents with the Agent\n",
    "\n",
    "Now we can use our agent to query all our PDF data sources intelligently!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fc6538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5 : Try to query the agent with a question about the documents you provided\n",
    "\n",
    "## YOUR CODE HERE\n",
    "# response = agent.chat(\"Your question here\")\n",
    "# print(response)\n",
    "\n",
    "# Example questions you could ask:\n",
    "# - \"What is the Bachelor's degree in Business Information Technology?\"\n",
    "# - \"List all the bachelor programs mentioned in all the documents\"\n",
    "# - \"Compare the programs offered in both documents\"\n",
    "\n",
    "# Some documentation to help you:\n",
    "# - https://docs.llamaindex.ai/en/stable/examples/agent/openai_agent/#chat-with-the-agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f475d1df",
   "metadata": {},
   "source": [
    "## Querying Specific PDF Sources\n",
    "\n",
    "You can also query individual PDF sources directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfd4fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 6 : Compare agent response vs direct query engine response\n",
    "\n",
    "if \"brochure-info-gestion\" in pdf_query_engines:\n",
    "   \n",
    "    # Exercise 6a : Ask the agent to focus on a specific document\n",
    "    ## YOUR CODE HERE\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # Exercise 6b : Query the direct query engine for comparison\n",
    "    ## YOUR CODE HERE  \n",
    "    \n",
    "    # Some documentation to help you:\n",
    "    # - https://docs.llamaindex.ai/en/stable/module_guides/deploying/query_engine/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285e1705",
   "metadata": {},
   "source": [
    "**Key Differences between Agent and Direct Query Engine:**\n",
    "\n",
    "1. **Agent approach**: \n",
    "   - Can reason about which tools to use\n",
    "   - Can combine information from multiple sources\n",
    "   - Provides more contextual and conversational answers\n",
    "   - Better for complex queries that span multiple documents\n",
    "   - More flexible and intelligent\n",
    "\n",
    "2. **Direct query engine**: \n",
    "   - Faster for simple queries on a single document\n",
    "   - More direct and focused on specific content\n",
    "   - Lacks reasoning capabilities\n",
    "   - Better for straightforward information retrieval\n",
    "\n",
    "**When to use which:**\n",
    "- Use the **agent** for complex questions, comparisons, or when you need information from multiple sources\n",
    "- Use **direct query engines** for fast, specific queries on individual documents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
